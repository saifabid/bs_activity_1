{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1 Activity: Classification & Predictions\n",
    "\n",
    "In this activity, we'll focus on 3 concepts\n",
    "- Identifying if the problem we're faced with is a prdiction or classification task\n",
    "- Applying K-NN to identify types of breast cancer tumors\n",
    "- Apply linear regression to help our animal shelter we saw in class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Task Identification\n",
    "\n",
    "In data science, we're often given a business problem and have some existing data in the company (or may have to go collect new data). However it isn't always clear what kind of machine learning problem we're solving. It's up to us as practitioners to take the business problem and convert it to the machine learning problem based on what we know.\n",
    "\n",
    "In this weeks class we learned about classification and prediction tasks. While these sound similar there was a key distiction between the two, could you recall what it is ?\n",
    "\n",
    "In the following exercise, we'll go a few business problems and it'll be up to you identify if we should tackle it with a classification task or a prediction task.\n",
    "\n",
    "**A.** As a real estate company I'd like to know if a given house will sell or not sell in 1 months time. My company has been collecting data for years not on various homes in the city. The data we collect includes parameters about the home, the neighborhood, the country it's in and also many social metrics around the home -> for example, we have number of tweets in the last 2 weeks about the neighborhood the home is in. We also do store if the home has sold in 1 month or not. We can provide you with abour 3 years of data, which ammounts to about 3 million homes, hope that helps!\n",
    "\n",
    "\n",
    "**Answer:** _please fill this out with an explaination_\n",
    "\n",
    "\n",
    "\n",
    "**B.** Trying to become the next big social influencer it's important that every tweet I make is positive. I've reached out to you're firm to screen my tweets before they get posted and block any that have a negative sentiment. Now it's easy to just get a account manager to do this, except I'm real fast with my tweets. I'm tweeting 80-90x a day at all times of the day. How could data science department take over my concerns and make sure nothing gets posted that shouldnt?\n",
    "\n",
    "**Answer:** _please fill this out with an explaination_\n",
    "\n",
    "\n",
    "**C.** At ecobee we sell tons of thermostats everyday. Now each house is different but for each house we can keep track of the tempreture of the house over time. We'd like to know ahead of time, given any time of day what the tempreture of the house might be. If we know this information, our data science department can use this information for more cooler features. We've reached out to your company and while we can't tell you what all the new features are, we can tell you what we'd like from you're team. Please advise how you would solve this.\n",
    "\n",
    "**Answer**:  _please fill this out with an explaination_\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Breast Cancer Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Loading the data\n",
    "\n",
    "The dataset we'll be exploring can be found here: `https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)`\n",
    "\n",
    "We've pulled in a local copy so don't worry about downloading it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "column_names = [\"id_number\",\"clump_thickness\",\"uniformity_cell_size\",\n",
    "                \"uniformity_cell_shape\", \"marginal_adhesion\",\n",
    "                \"single_epithelial_cell_size\", \"bare_nuclei\",\n",
    "                \"bland_chromatin\", \"normal_nucleoli\", \"mitosis\",\n",
    "                \"class\"]\n",
    "df = pd.read_csv(\"breast-cancer-wisconsin.csv\", names=column_names)\n",
    "df = df[(df[column_names] != '?').all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Exploring the dataset\n",
    "\n",
    "It's a good idea when starting any tasks to explore the dataset. In this case, see if you can determine the following information:\n",
    "\n",
    "1. Total number of samples \n",
    "2. Number of pateitns with a benign tumor (class 2)\n",
    "3. Number of patients with malignant tumor (class 4)\n",
    "4. % of users with each type of tumor\n",
    "\n",
    "Note: Be sure to show how you can extract all this information from the dataframe loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Fill in variables accordingly\n",
    "n_samples = None\n",
    "n_benign = None\n",
    "n_malignant = None \n",
    "per_benign = None\n",
    "per_malignant = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Prepare the dataset\n",
    "\n",
    "In this section, we will prepare the data for modeling, training and testing. The first task we'll need to do is extract our **target** and our **feature** columns into two seperate dataframe\n",
    "\n",
    "In this dataset, the target, or class we are trying to determine is in the column named \"class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Extract the features into a variable called X and the output column into a variable called y\n",
    "def feature_target_split(df):\n",
    "    X = None # Fill in variables accordingly\n",
    "    y = None\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Split data into train/test portions\n",
    "\n",
    "When we build a model in machine learning, we'd like to evaluate the model somehow before we put it to use in the \"real world\".\n",
    "\n",
    "A typical apporach is to take our entire dataset and split it into a **train** and **test** portion. The reason for this is because if you trained on the entire dataset, and then used the same data to check how well your model worked, you'll get a very inaccurate measure of success. Remember the point of machine learning models is to learn patterns and then apply them to **new** data. The  **test** set simulates data our model has never seen before.\n",
    "\n",
    "Sklearn provides a method called **train_test_split** which allows us to split our data into various proportions. Typically a 70% train, 30% test is a good place to start.\n",
    "\n",
    "(`http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html`)\n",
    "\n",
    "\n",
    "You're task will be to split your data into training and testing data with 70% training and 30% test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split_data(X, y, test_size):\n",
    "    X_train, X_test, y_train, y_test = None # Fill this in (approx 1 line.)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Training and Evaluating your model\n",
    "\n",
    "In class, we learned about an algorithem known as K-NN. The goal for K-NN was to pick K \"closest\" points to the point in question and make a choose the majority.\n",
    "\n",
    "In this section, we're going to see how our model reacts to differnt values of K.\n",
    "\n",
    "Your task is to first write a function get_clf, which will init a KNN classifier with a predefined value of K. The doccumentation for the classifier can be found here: `http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html`\n",
    "\n",
    "**n_neighbors** parameter which controls K. For the other parameters, leave them as default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def get_clf(k):\n",
    "    clf = None # Approx 1 line.\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to **fit** (train) our model based on our input data. To do this, call `clf.fit(input_data)`. \n",
    "\n",
    "What is the input to the fit method? Is it the X, X_train, X_test, y, y_train, y_test ?\n",
    "\n",
    "Hint: Dont forget to call get_clf and use any other methods you've defined earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "k = None # Define a k\n",
    "clf = None # Fill in \n",
    "X,y = None # Fill in \n",
    "X_train, X_test, y_train, y_test = None  # Is it the X, X_train, X_test, y, y_train, y_test \n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! If you've gotten this far without errors, you've trained and created a model!\n",
    "\n",
    "Now we want to evaluate how good our model is. \n",
    "\n",
    "\"Good\" in machine learning can mean many things, and often times it depends on the problem at hand. In classification tasks, accuracy is a good measure of \"good\". Accuracy is defined as the **Total number of samples correctly identified / Total number of samples**\n",
    "\n",
    "Given this, would a high accruacy be what we want, or a low accuracy score? \n",
    "\n",
    "Answer: _please fill this out with an explaination_\n",
    "\n",
    "On that note, here's your next task! \n",
    "\n",
    "Now that the model is fit, determine the accuracy of the model. To do this, use the `accuracy_score` in sklearn. Doccumentation can be found here: `http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html` along with the `clf.predict` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "X_predict = None # Fill in\n",
    "y_pred = None # Fill in \n",
    "y_real = None # Fill in \n",
    "score = None # Fill in\n",
    "print (\"Accuracy {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K value: _please fill this in_\n",
    "\n",
    "Accuracy Score: _please fill this in_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Tuning to different values of K\n",
    "\n",
    "Often times, depending on the value of K you have chosen, you'll find another value might give you better results. In the following section, try out different value and report on their accuracy score. Why do you think different values are giving different results?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Fill in all None's accordingly\n",
    "k = None\n",
    "clf =  get_clf(k)\n",
    "X_fit, y_fit = None # Is it the X, X_train, X_test, y, y_train, y_test ? \n",
    "clf.fit(X_fit, y_fit)\n",
    "X_predict = None \n",
    "y_pred = None \n",
    "y_real = None\n",
    "score = accuracy_score(y_real, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G: As a bonus, try using the methods above to see what happens if we give a bigger test set / smaller train set\n",
    "\n",
    "Remember machine learning is all about \"learning\" from the past and applying those patterns. What does your intuiton say about the performance of our classifier if our train set was very small? \n",
    "\n",
    "Your bonus task here is to test out your intuition and seeing what happens to your performance (accuracy) as the train size changes.\n",
    "\n",
    "Does your intuition hold up?\n",
    "\n",
    "**Answer:** _Fill this out once you have implemented the code and tested the intuition_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Use the functions and logic implemented above to evaluate the effect of different test and train sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Identifying relationship between age and bloodpressure \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: Load the data\n",
    "\n",
    "\n",
    "As like before when we were in classifing, we need to first load our data in. \n",
    "In this case, we'll be looking at the example of the animal shelter who price their pets based on their size.\n",
    "\n",
    "\n",
    "In this exerscise we'll take a more free form approach. In the last exercise we gave a bit of start code for each task to guide you thoruhg the task. In this one, we'll leave the cells mostly empty and give hints in the description of the task.\n",
    "\n",
    "Good luck!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "df_shelter = pd.read_csv('dataset.csv')\n",
    "df_shelter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Exploration \n",
    "\n",
    "\n",
    "In this section we'd like to better understand the data. Unlike before, here we only have (or atleast we hope we have) two attributes - price and size. \n",
    "\n",
    "Lets start by verifying that.\n",
    "\n",
    "\n",
    "Task: use the `df_shelter` dataframe to verify the columns you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Verify the columns here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes! What's this \"Unnamed: 0\" column doing?! It seems to be the same as the index, so we can get rid of it. \n",
    "\n",
    "Task: Remove the column \"Unnamed: 0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Remove the column here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now, that we've cleaned up the data just a bit, lets continue the exploration.\n",
    "\n",
    "Task:\n",
    "\n",
    "- How many animals are in the shelter?\n",
    "- Which index is the smallest animal?\n",
    "- Which index is the largest animal?\n",
    "- Which index is more expensive animal?\n",
    "- Which animal is the cheapest?\n",
    "- Which attribute is our \"independant\" variable?\n",
    "- Which attribute is our \"dependant\" variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Program the solution to all question in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Data Visulization\n",
    "\n",
    "In class we learned that depending on the data distribution we might want to do a \"linear\" regression, or a \"polynomial\" regression depending on our data is distributed.\n",
    "\n",
    "When there are many independant variables, determining this can become a bit more difficult and we'll see techniques in later lessons on how to approach this. However, for now in our problem, we have only 1 independant and 1 dependant variable. Therefore lets figure out if we'll need a linear distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Plot the dependant variable(y axis) vs independant variable(x axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! \n",
    "\n",
    "If you've managed to plot the graph correctly, the animal prices should show up on the vertical axis, and the size should be on the horizontal axis. \n",
    "\n",
    "Once you have that plotted, you'll notice this dataset does infact seem to follow a \"linear\" pattern. \n",
    "\n",
    "It looks like we'll be able to use linear regression here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Train Test Splits\n",
    "\n",
    "In this section like in the case for classification, lets use the `train_test_split` method from sklearn to split our data.\n",
    "\n",
    "Because in this case we only have 100 data points, lets keep our training set at 80% and our test set 20%\n",
    "\n",
    "Task:\n",
    "\n",
    "- Write a function that splits the data into 80% train, 20% test sets \n",
    "\n",
    "Hint: Take a look back at how you did this for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Write a function to split the data in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Model Building\n",
    "\n",
    "When we did classification, we used sklearn's KNN package to build our model. Sklearn also provides a similar package for prediction tasks. It's doccumentation can be found here: `http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html`\n",
    "\n",
    "In this part your task is as follows:\n",
    "\n",
    "- Use the LinearRegression package to init your predictor\n",
    "- Fit the model (train) with your training data\n",
    "\n",
    "Note: In lecture we learned about finding the \"optimal\" slope and y intercept. When we call \"fit\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Init and train your model in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Evaluate your model\n",
    "\n",
    "You have your model trained, but as before, lets evaluate it's performance before we send it out to the field.\n",
    "\n",
    "In this section, you the predictors `.predict` method to get it's results for the test set.\n",
    "\n",
    "In prediction tasks, to measure \"goodness\", instead of accuracy, we can use the mean squared error. The mean squared error goes over every sample in question and sums the squared difference between it's actual value and its value based on the model. In sklearn we have access to a method to do this, called `mean_squared_error` in the metrics package. Doccumentation can be found here: `http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error`\n",
    "\n",
    "Based on its description, would you think a higher MSE (mean squared error) is better or worse then a smaller one?\n",
    "\n",
    "**Answer:** _please explain your answer here_\n",
    "\n",
    "Furthermore here is the task for this section:\n",
    "\n",
    "- Use `.predict` to get the predictions for your test set\n",
    "- Evaluate your model using the mean squared error function\n",
    "- Identify the models slope and intercept. (Hint: View the doccumentation and google around to see how we can do this with the sklearn model)\n",
    "\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "- Mean squared error: _please fill this in_\n",
    "- y-intercept: _please fill this in_\n",
    "- Slope: _please fill this in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Use this cell to evaluate your model and determine the model parameters"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "nteract": {
   "version": "0.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
